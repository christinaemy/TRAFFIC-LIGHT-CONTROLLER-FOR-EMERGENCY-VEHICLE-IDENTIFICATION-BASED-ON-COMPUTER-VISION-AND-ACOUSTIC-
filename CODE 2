AVEHICLE IDENTIFICATION BASED ON COMPUTER 
                VISION AND ACOUSTIC SIGNALS

CODE:

SOURCE CODE 
from keras.models import Sequential 
from keras.layers import Convolution2D 
from keras.layers import MaxPooling2D 
from keras.layers import Flatten 
from keras.layers import Dense 
from keras.models import model_from_json 
import matplotlib.pyplot as plt 
import warnings 
warnings.filterwarnings('ignore') 
batch_size = 32 
from tensorflow.keras.preprocessing.image import ImageDataGenerator 
# All images will be rescaled by 1./255 
train_datagen = ImageDataGenerator(rescale=1/255) 
# Flow training images in batches of 128 using train_datagen generator 
train_generator = train_datagen.flow_from_directory( 
'DataSet/train/', # This is the source directory for training images 
target_size=(200, 200), # All images will be resized to 200 x 200 
batch_size=batch_size, 
# Specify the classes explicitly 
classes = ['Ambulance','Bicycle','Bus','Car','Motorcycle','Tank','Taxi','Truck'],# Since we use categorical_crossentropy loss, we need categorical labels 
class_mode='categorical') 
import tensorflow as tf 
model = tf.keras.models.Sequential([ 
# Note the input shape is the desired size of the image 200x 200 with 3 bytes color 
# The first convolution 
tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3)), 
tf.keras.layers.MaxPooling2D(2, 2), 
# The second convolution 
tf.keras.layers.Conv2D(32, (3,3), activation='relu'), 
tf.keras.layers.MaxPooling2D(2,2), 
# The third convolution 
tf.keras.layers.Conv2D(64, (3,3), activation='relu'), 
tf.keras.layers.MaxPooling2D(2,2), 
# The fourth convolution 
tf.keras.layers.Conv2D(64, (3,3), activation='relu'), 
tf.keras.layers.MaxPooling2D(2,2), 
# The fifth convolution 
tf.keras.layers.Conv2D(64, (3,3), activation='relu'), 
tf.keras.layers.MaxPooling2D(2,2), 
# Flatten the results to feed into a dense layer 
tf.keras.layers.Flatten(), 
35# 128 neuron in the fully-connected layer 
tf.keras.layers.Dense(128, activation='relu'), 
# 5 output neurons for 5 classes with the softmax activation 
tf.keras.layers.Dense(8, activation='softmax')]) 
model.summary() 
from tensorflow.keras.optimizers import RMSprop 
early = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5) 
model.compile(loss='categorical_crossentropy', 
optimizer=RMSprop(lr=0.001), 
metrics=['accuracy']) 
total_sample=train_generator.n 
n_epochs = 10 
history = model.fit_generator( 
train_generator, 
steps_per_epoch=int(total_sample/batch_size), 
epochs=n_epochs, 
verbose=1) 
model.save('model.h5') 
acc = history.history['accuracy'] 
loss = history.history['loss'] 
epochs = range(1, len(acc) + 1) 
# Train and validation accuracy 
3637 
plt.plot(epochs, acc, 'b', label='Training accurarcy') 
plt.title('Training accurarcy') 
plt.legend() 
plt.figure() 
# Train and validation loss 
plt.plot(epochs, loss, 'b', label='Training loss') 
plt.title('Training loss') 
plt.legend() 
plt.show() 
import sys 
import pathlib 
working_dir_path = pathlib.Path().absolute() 
if sys.platform.startswith('win32'): 
TRAINING_FILES_PATH = str(working_dir_path) + '\\features\\' 
SAVE_DIR_PATH = str(working_dir_path) + '\\joblib_features\\' 
MODEL_DIR_PATH = str(working_dir_path) + '\\model\\' 
TESS_ORIGINAL_FOLDER_PATH = str(working_dir_path) + 
'\\sound_set_data\\' 
EXAMPLES_PATH = str(working_dir_path) + '\\examples\\' 
else: 
TRAINING_FILES_PATH = str(working_dir_path) + '/features/' 
SAVE_DIR_PATH = str(working_dir_path) + '/joblib_features/' 
MODEL_DIR_PATH = str(working_dir_path) + '/model/'38 
TESS_ORIGINAL_FOLDER_PATH = str(working_dir_path) + '/sound_set_data/' 
EXAMPLES_PATH = str(working_dir_path) + '/examples/' 
""" 
This files creates the X and y features in joblib to be used by the predictive models. 
""" 
import os 
import time 
import joblib 
import librosa 
import numpy as np 
from config import SAVE_DIR_PATH 
from config import TRAINING_FILES_PATH 
class CreateFeatures: 
@staticmethod 
def features_creator(path, save_dir) -> str: 
""" 
This function creates the dataset and saves both data and labels in two files, X.joblib 
and y.joblib in the joblib_features folder. With this method, you can persist your 
features and train quickly new machine learning models instead of reloading the 
featuresevery time with this pipeline. 
"""lst = [] 
start_time = time.time() 
for subdir, dirs, files in os.walk(path): 
for file in files: 
print(file) 
try: 
# Load librosa array, obtain mfcss, store the file and the mcss information in a new 
array 
X, sample_rate = librosa.load(os.path.join(subdir, file), 
res_type='kaiser_fast') 
mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, 
n_mfcc=40).T, axis=0) 
# The instruction below converts the labels (from 1 to 8) to a series from 0 to 7 
# This is because our predictor needs to start from 0 otherwise it will try to predict 
also 0. 
file = str(file[0:3]) 
print(file) 
if file == 'amb': 
file = 0 
else: 
file = 1 
print(file) 
39arr = mfccs, file 
print(arr) 
lst.append(arr) 
# If the file is not valid, skip it 
except ValueError as err: 
print(err) 
continue 
print("--- Data loaded. Loading time: %s seconds ---" % (time.time() - start_time)) 
# Creating X and y: zip makes a list of all the first elements, and a list of all the 
second elements. 
X, y = zip(*lst) 
# Array conversion 
X, y = np.asarray(X), np.asarray(y) 
# Array shape check 
print(X.shape, y.shape) 
# Preparing features dump 
X_name, y_name = 'X.joblib', 'y.joblib' 
joblib.dump(X, os.path.join(save_dir, X_name)) 
joblib.dump(y, os.path.join(save_dir, y_name)) 
return "Completed" 
if __name__ == '__main__': 
print('Routine started') 
40FEATURES = CreateFeatures.features_creator(path=TRAINING_FILES_PATH, 
save_dir=SAVE_DIR_PATH) 
print('Routine completed.') 
""" 
This file can be used to try a live prediction. 
""" 
import keras 
import librosa 
import numpy as np 
from config import EXAMPLES_PATH 
from config import MODEL_DIR_PATH 
class LivePredictions: 
""" 
Main class of the application. 
""" 
def __init__(self, file): 
""" 
Init method is used to initialize the main parameters. 
""" 
self.file = file 
self.path = MODEL_DIR_PATH + 'sound_Model.h5' 
41self.loaded_model = keras.models.load_model(self.path) 
def make_predictions(self): 
""" 
Method to process the files and create your features. 
""" 
data, sampling_rate = librosa.load(self.file) 
mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, 
axis=0) 
x = np.expand_dims(mfccs, axis=2) 
x = np.expand_dims(x, axis=0) 
predictions = self.loaded_model.predict_classes(x) 
print( "Prediction is", " ", self.convert_class_to_emotion(predictions)) 
@staticmethod 
def convert_class_to_emotion(pred): 
""" 
Method to convert the predictions (int) into human readable strings. 
""" 
label_conversion = {'0': 'ambulance', 
'1': 'traffic' 
} 
for key, value in label_conversion.items(): 
if int(key) == pred: 
42label = value 
return label 
if __name__ == '__main__': 
live_prediction = LivePredictions(file=EXAMPLES_PATH + 'sound_1.wav') 
live_prediction.loaded_model.summary() 
live_prediction.make_predictions() 
live_prediction = LivePredictions(file=EXAMPLES_PATH + 'sound_401.wav') 
live_prediction.make_predictions() 
""" 
Neural network train file. 
""" 
import os 
import joblib 
import numpy as np 
import matplotlib.pyplot as plt 
from keras.layers import Dense 
from keras.layers import Conv1D 
from keras.layers import Flatten 
from keras.layers import Dropout 
from keras.layers import Activation 
from keras.models import Sequential 
from sklearn.metrics import confusion_matrix 
43from sklearn.metrics import classification_report 
from sklearn.model_selection import train_test_split 
from config import SAVE_DIR_PATH 
from config import MODEL_DIR_PATH 
class TrainModel: 
@staticmethod 
def train_neural_network(X, y) -> None: 
""" 
This function trains the neural network. 
""" 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, 
random_state=42) 
x_traincnn = np.expand_dims(X_train, axis=2) 
x_testcnn = np.expand_dims(X_test, axis=2) 
print(x_traincnn.shape, x_testcnn.shape) 
model = Sequential() 
model.add(Conv1D(64, 5, padding='same', 
input_shape=(40, 1))) 
model.add(Activation('relu')) 
model.add(Dropout(0.2)) 
model.add(Flatten()) 
model.add(Dense(2)) 
model.add(Activation('softmax')) 
44print(model.summary) 
model.compile(loss='sparse_categorical_crossentropy', 
optimizer='rmsprop', 
metrics=['accuracy']) 
cnn_history = model.fit(x_traincnn, y_train, 
batch_size=16, epochs=50, 
validation_data=(x_testcnn, y_test)) 
# Loss plotting 
plt.plot(cnn_history.history['loss']) 
plt.plot(cnn_history.history['val_loss']) 
plt.title('model loss') 
plt.ylabel('loss') 
plt.xlabel('epoch') 
plt.legend(['train', 'test'], loc='upper left') 
plt.savefig('loss.png') 
plt.close() 
# Accuracy plotting 
plt.plot(cnn_history.history['accuracy']) 
plt.plot(cnn_history.history['val_accuracy']) 
plt.title('model accuracy') 
plt.ylabel('acc') 
plt.xlabel('epoch') 
45plt.legend(['train', 'test'], loc='upper left') 
plt.savefig('accuracy.png') 
predictions = model.predict_classes(x_testcnn) 
new_y_test = y_test.astype(int) 
matrix = confusion_matrix(new_y_test, predictions) 
print(classification_report(new_y_test, predictions)) 
print(matrix) 
model_name = 'sound_Model.h5' 
# Save model and weights 
if not os.path.isdir(MODEL_DIR_PATH): 
os.makedirs(MODEL_DIR_PATH) 
model_path = os.path.join(MODEL_DIR_PATH, model_name) 
model.save(model_path) 
print('Saved trained model at %s ' % model_path) 
if __name__ == '__main__': 
print('Training started') 
print(SAVE_DIR_PATH + 'X.joblib') 
X = joblib.load(SAVE_DIR_PATH + 'X.joblib') 
y = joblib.load(SAVE_DIR_PATH + 'y.joblib') 
NEURAL_NET = TrainModel.train_neural_network(X=X, y=y) 
from flask import Flask, render_template, flash, request, session, send_file 
from flask import render_template, redirect, url_for, request 
46import warnings 
import datetime 
app = Flask(__name__) 
app.config['DEBUG'] 
app.config['SECRET_KEY'] = '7d441f27d441f27567d441f2b6176a' 
@app.route("/") 
def homepage(): 
return render_template('index.html') 
@app.route("/Test") 
def Test(): 
return render_template('Test.html') 
@app.route("/ImageTest") 
def ImageTest(): 
return render_template('ImageTest.html') 
@app.route("/imgetest", methods=['GET', 'POST']) 
def imgetest(): 
if request.method == 'POST': 
import tensorflow as tf 
import numpy as np 
from keras.preprocessing import image 
file = request.files['fileupload'] 
file.save('static/upload/Test.jpg') 
47fname = 'static/upload/Test.jpg' 
import warnings 
warnings.filterwarnings('ignore') 
classifierLoad = tf.keras.models.load_model('model.h5') 
test_image = image.load_img('static/upload/Test.jpg', target_size=(200, 200)) 
test_image = np.expand_dims(test_image, axis=0) 
result = classifierLoad.predict(test_image) 
print(result[0][0]) 
res = '' 
result1 = '' 
if result[0][0] == 1: 
res = 'Ambulance' 
result1 = 'Emergency' 
return render_template('Test.html', result=res, gry=fname) 
elifresult[0][1] == 1: 
res = 'Bicycle' 
result1 = 'Normal' 
elifresult[0][2] == 1: 
res = 'Bus' 
result1 = 'Normal' 
elifresult[0][3] == 1: 
res = 'Car' 
48result1 = 'Normal' 
elifresult[0][4] == 1: 
res = 'Motorcycle' 
result1 = 'Normal' 
elifresult[0][5] == 1: 
res = 'Tank' 
result1 = 'Normal' 
elifresult[0][6] == 1: 
res = 'Taxi' 
result1 = 'Normal' 
elifresult[0][7] == 1: 
res = 'Truck' 
result1 = 'Normal' 
return render_template('ImageTest.html', result=res, result1=result1, gry=fname) 
@app.route("/testsound", methods=['GET', 'POST']) 
def testsound(): 
if request.method == 'POST': 
file = request.files['fileupload'] 
file.save('static/Out/' + file.filename) 
live_prediction = LivePredictions(file='static/Out/' + file.filename) 
live_prediction.loaded_model.summary() 
live_prediction.make_predictions() 
49res = session["out"] 
gry = '' 
if res == "ambulance": 
res = 'Ambulance' 
result1 = 'Emergency' 
gry = 'static/emoji/green.jpg' 
elif res == "traffic": 
res = 'Traffic' 
result1 = 'Normal' 
gry = 'static/emoji/red.jpg' 
return render_template('Test.html', result=res, result1=result1, gry=gry) 
import keras 
import librosa 
import numpy as np 
from config import EXAMPLES_PATH 
from config import MODEL_DIR_PATH 
class LivePredictions: 
""" 
Main class of the application. 
""" 
def __init__(self, file): 
""" 
50Init method is used to initialize the main parameters. 
""" 
self.file = file 
self.path = MODEL_DIR_PATH + 'sound_Model.h5' 
self.loaded_model = keras.models.load_model(self.path) 
def make_predictions(self): 
""" 
Method to process the files and create your features. 
""" 
data, sampling_rate = librosa.load(self.file) 
mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, 
axis=0) 
x = np.expand_dims(mfccs, axis=2) 
x = np.expand_dims(x, axis=0) 
predictions = self.loaded_model.predict_classes(x) 
print("Prediction is", " ", self.convert_class_to_emotion(predictions)) 
session["out"] = self.convert_class_to_emotion(predictions) 
@staticmethod 
def convert_class_to_emotion(pred): 
""" 
Method to convert the predictions (int) into human readable strings. 
""" 
label_conversion = {'0': 'ambulance', 
5152 
'1': 'traffic', 
} 
for key, value in label_conversion.items(): 
if int(key) == pred: 
label = value 
return label 
def sendmsg(targetno, message): 
import requests 
requests.post( 
"http://smsserver9.creativepoint.in/api.php?username=fantasy&password=596692&t 
o=" + targetno + "&from=FSSMSS&message=Dear user yourmsg is " + message + " 
Sent By FSMSG 
FSSMSS&PEID=1501563800000030506&templateid=1507162882948811640") 
if __name__ == '__main__': 
app.run(debug=True, use_reloader=True)
